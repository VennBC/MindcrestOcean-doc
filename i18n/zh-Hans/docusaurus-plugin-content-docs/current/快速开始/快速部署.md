---
sidebar_position: 2
sidebar_label: 部署手册
---

# 一、单机部署
## 基础环境依赖

 - docker == 1.27.x   docker 存储目录>1T
 - kubernetes = 1.21~1.25
 - kubectl == 1.24 
 - nfs/ceph等分布式文件系统 挂载到每台机器的 /data/k8s/ （单机可忽略）
 - 数据库接口地址 mysql，没有可忽略使用cube-studio自带的
 - 单机 磁盘>=1000G 单机磁盘容量要求不大，仅做镜像容器的的存储  
 - 控制端机器1-2台 cpu>=16 mem>=32G  
 - 任务端cpu/gpu机器	根据需要自行配置和扩容，gpu安装对应厂商的要求安装好机器驱动
 - IB/RDMA网络	自动安装机器驱动和IB卡
 - 系统 ubuntu 20.04 ubuntu 22.04 或者centos7或者centos8

平台完成部署之后如下:



## 部署提前预备内容

1、分布式存储，挂载到/data/k8s目录下（单机可忽略）。

nfs分布式存储示例：参考cube-studio/install/kubernetes/nfs/NFS离线部署.md

2、私有镜像仓库，在每台机器的docker配置中添加Insecure Registries(体验可忽略)

参考：cube-studio/install/harbor/readme.md

3、gpu机器要安装nvidia-docker2，gpu机器安装对应的驱动，IB设备也需要安装对应的驱动(cpu机器可忽略)

参考：cube-studio/install/rancher

### 1、未有k8s的用户

可以参考视频，先使用rancher部署k8s，再部署cube-studio

[单机部署视频](https://www.bilibili.com/video/BV18r4y147oj/)

也可以查看使用rancher部署k8s的文档，可以查看cube-studio/install/kubernetes/rancher/readme.md

### 2、对于已有k8s的用户

1、对于ipvs模式的k8s，
  （1）要将start.sh脚本最后面的`kubectl patch`注释掉。然后手动释放istio-system命名空间 istio-ingressgateway,服务类型改为NodePort。
  （2）将配置文件install/kubernetes/cube/overlays/config/config.py中的K8S_NETWORK_MODE 改为ipvs

2、服务可用端口范围要放大到10~60000

3、平台入口是istio-system命名空间 istio-ingressgateway，不是cube-studio的前端部分

平台部署命令：

将k8s集群的kubeconfig文件复制到install/kubernetes/config文件中,对于双网卡的同学，记得rancher里面current-context切换为内网的连接形式，然后执行如下命令，其中xx.xx.xx.xx为机器内网的ip（不是外网ip）
```
# 在k8s worker机器上执行
sh start.sh xx.xx.xx.xx
```

kubeconfig文件位置

![在这里插入图片描述](https://img-blog.csdnimg.cn/direct/20677dc5fefb41ca99969144d158e721.png)

### 3、隔离内网部署




4、创建企业自己的镜像仓库，在web界面，在线开发-镜像仓库，添加自己的仓库地址和账号密码。注意hubsecret不要删除

5、修改config.py文件中REPOSITORY_ORG为自己的镜像仓库地址，HUBSECRET添加自己上一步配置的k8s hubsecret，并将配置更新到infra/kubeflow-dashboard-config的configmap中。

## 修改为非80端口

修改istio-system命名空间下面名为istio-ingressgateway的service，将服务类型改为NodePort。将80端口的nodePort改为其他可以访问的端口，注意不要删除80端口的配置，因为在gateway中会读取这个80参数。

## 域名访问

修改 install/kubernetes/gateway.yaml,将其中的host参数 *  修改为域名。然后重新部署这个gateway.yaml文件

修改域名后notebook要重新reset才能打开。

## 内部ip和外部ip


## nginx 反向代理istio-ingressgateway

有时候浏览器只能打开物理机ip，而我们部署cube-studio使用的是虚拟机。需要添加nginx代理，注意nginx访问超时时常要设置大一些，不然websocket协议的webshell执行命令会失败

nginx配置参考：myapp/install/kubernetes/nginx-https/nginx.conf


## 部署后排查

0、在内网中会存在，kubectl工具不存在，无法下载，可以查看修改下start.sh脚本，手动下载kubectl。

1、如果k8s采用的是ipvs网络模式，修改istio-ingressgateway为nodeport模式，而不是externalIPs模式，并在配置文件config.py中将iptables修改为ipvs

2、查看机器lable是否添加
```
kubectl label node $node train=true cpu=true notebook=true service=true org=public istio=true knative=true kubeflow=true kubeflow-dashboard=true mysql=true redis=true monitoring=true logging=true --overwrite
```

3、pv和pvc是否绑定。有些k8s平台会自动为pvc添加Storage Classes，需要对应pv也添加完成绑定
  
4、kube-system命名空间coredns是否正常，
 - 4.1、可以放开防火墙
```
/sbin/iptables -P FORWARD ACCEPT
/sbin/iptables -P INPUT ACCEPT
/sbin/iptables -P OUTPUT ACCEPT
```
放开防火墙后重启coredns 的pod
 - 4.2、可以查看53端口是否被占用，比如bind服务，关闭主机原有53端口服务(注意机器重启后可能原53端口占用的服务被重新打开)。

5、infra命名空间其他组件是否成功，会链接mysql完成数据库初始化。kubeflow数据库由kubeflow-dashboard.infra组件完成初始化。
 - 5.1 数据库如果库表不全，可以把对应库删掉，重启相应组件。rm -rf /data/k8s/infra/mysql，然后重启mysql，再重启kubeflow-dashboard
 - 5.2  如果kubeflow-dashboard报core dump，则可能是linux系统内核版本太低，需要升级系统内核

6、istio-system空间，istio-ingressgateway的svc是否externalIPs形式暴露了内网ip。 如果有双网卡， 在执行sh start.sh xx.xx.xx.xx时，使用的是内网ip，浏览器打开的是外网ip

6、istio-ingressgateway暴露80以后，仍然无法打开，可能原因（1）80被内网封禁（2）80倍其他服务占用（3）没有禁用nginx-ingress (4)防火墙限制，可以`/sbin/iptables -P FORWARD ACCEPT`

7、istio-ingressgateway暴露其他端口，如果80端口被占用了，可以修改 istio-system/svc/istio-ingressgateway 类型为NodePort

内网机器需要安装了docker，docker-compose，iptables

# 二、内网离线部署

## 1.内网中有可以联网的机器

###  联网机器设置代理服务器

联网机器上设置nginx代理软件源，参考install/kubernetes/nginx-https/apt-yum-pip-source.conf

启动nginx代理访问

需要监听80和443端口
```bash
docker run --name proxy-repo -d --restart=always --network=host -v $PWD/nginx-https/apt-yum-pip-source.conf:/etc/nginx/nginx.conf nginx 
```

### 在内网机器上配置host

host
```bash
<出口服务器的IP地址>    mirrors.aliyun.com
<出口服务器的IP地址>    ccr.ccs.tencentyun.com
<出口服务器的IP地址>    registry-1.docker.io
<出口服务器的IP地址>    auth.docker.io
<出口服务器的IP地址>    hub.docker.com
<出口服务器的IP地址>    www.modelscope.cn
<出口服务器的IP地址>    modelscope.oss-cn-beijing.aliyuncs.com
<出口服务器的IP地址>    archive.ubuntu.com
<出口服务器的IP地址>    security.ubuntu.com
<出口服务器的IP地址>    cloud.r-project.org
<出口服务器的IP地址>    deb.nodesource.com
<出口服务器的IP地址>    docker-76009.sz.gfp.tencent-cloud.com
```

添加新的host要重启下kubelet   docker restart kubelet

如果代理机器没法占用80和443，需要使用iptable尝试转发。

iptables
```bash
sudo iptables -t nat -A PREROUTING -p tcp --dport 80 -d mirrors.aliyun.com -j DNAT --to-destination <出口服务器的IP地址>:<出口服务器的端口>
```

### k8s配置域名解析

k8s中修改 kube-system命名空间，coredns的configmap，添加 需要访问的地址 的地址映射
```bash
{
  "Corefile": ".:53 {
        errors
        health {
          lameduck 5s
        }
        ready
        kubernetes cluster.local in-addr.arpa ip6.arpa {
          pods insecure
          fallthrough in-addr.arpa ip6.arpa
        }
        # 自定义host
        hosts {
            <出口服务器的IP地址>    mirrors.aliyun.com
                <出口服务器的IP地址>    ccr.ccs.tencentyun.com
                <出口服务器的IP地址>    registry-1.docker.io
                <出口服务器的IP地址>    auth.docker.io
                <出口服务器的IP地址>    hub.docker.com
                <出口服务器的IP地址>    www.modelscope.cn
                <出口服务器的IP地址>    modelscope.oss-cn-beijing.aliyuncs.com
                <出口服务器的IP地址>    archive.ubuntu.com
                <出口服务器的IP地址>    security.ubuntu.com
                <出口服务器的IP地址>    cloud.r-project.org
                <出口服务器的IP地址>    deb.nodesource.com
                <出口服务器的IP地址>    docker-76009.sz.gfp.tencent-cloud.com
          fallthrough
        }
        prometheus :9153
        forward . \"/etc/resolv.conf\"
        cache 30
        loop
        reload
        loadbalance
    } # STUBDOMAINS - Rancher specific change
    "
}
```
重启coredns的pod



